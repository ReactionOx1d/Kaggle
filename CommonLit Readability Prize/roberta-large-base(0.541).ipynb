{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4778ff2c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-07-18T19:27:47.333631Z",
     "iopub.status.busy": "2021-07-18T19:27:47.330143Z",
     "iopub.status.idle": "2021-07-18T19:27:47.411034Z",
     "shell.execute_reply": "2021-07-18T19:27:47.411753Z",
     "shell.execute_reply.started": "2021-07-18T19:15:09.946885Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.110718,
     "end_time": "2021-07-18T19:27:47.412127",
     "exception": false,
     "start_time": "2021-07-18T19:27:47.301409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/huggingface-roberta-variants/roberta-large-mnli/roberta-large-mnli/config.json\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large-mnli/roberta-large-mnli/merges.txt\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large-mnli/roberta-large-mnli/README.md\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large-mnli/roberta-large-mnli/tokenizer.json\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large-mnli/roberta-large-mnli/vocab.json\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large-mnli/roberta-large-mnli/tf_model.h5\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large-mnli/roberta-large-mnli/pytorch_model.bin\n",
      "/kaggle/input/huggingface-roberta-variants/xlm-roberta-large/xlm-roberta-large/config.json\n",
      "/kaggle/input/huggingface-roberta-variants/xlm-roberta-large/xlm-roberta-large/tokenizer.json\n",
      "/kaggle/input/huggingface-roberta-variants/xlm-roberta-large/xlm-roberta-large/pytorch_model.bin\n",
      "/kaggle/input/huggingface-roberta-variants/xlm-roberta-large/xlm-roberta-large/sentencepiece.bpe.model\n",
      "/kaggle/input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base/config.json\n",
      "/kaggle/input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base/tf_model.h5\n",
      "/kaggle/input/huggingface-roberta-variants/tf-xlm-roberta-base/tf-xlm-roberta-base/sentencepiece.bpe.model\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/rust_model.ot\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/config.json\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/merges.txt\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/README.md\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/tokenizer.json\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/vocab.json\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/tf_model.h5\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/dict.txt\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/pytorch_model.bin\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-base/roberta-base/flax_model.msgpack\n",
      "/kaggle/input/huggingface-roberta-variants/distilroberta-base/distilroberta-base/rust_model.ot\n",
      "/kaggle/input/huggingface-roberta-variants/distilroberta-base/distilroberta-base/config.json\n",
      "/kaggle/input/huggingface-roberta-variants/distilroberta-base/distilroberta-base/merges.txt\n",
      "/kaggle/input/huggingface-roberta-variants/distilroberta-base/distilroberta-base/README.md\n",
      "/kaggle/input/huggingface-roberta-variants/distilroberta-base/distilroberta-base/tokenizer.json\n",
      "/kaggle/input/huggingface-roberta-variants/distilroberta-base/distilroberta-base/vocab.json\n",
      "/kaggle/input/huggingface-roberta-variants/distilroberta-base/distilroberta-base/tf_model.h5\n",
      "/kaggle/input/huggingface-roberta-variants/distilroberta-base/distilroberta-base/dict.txt\n",
      "/kaggle/input/huggingface-roberta-variants/distilroberta-base/distilroberta-base/pytorch_model.bin\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large/roberta-large/config.json\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large/roberta-large/merges.txt\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large/roberta-large/README.md\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large/roberta-large/tokenizer.json\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large/roberta-large/vocab.json\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large/roberta-large/tf_model.h5\n",
      "/kaggle/input/huggingface-roberta-variants/roberta-large/roberta-large/pytorch_model.bin\n",
      "/kaggle/input/huggingface-roberta-variants/pytorch-xlm-roberta-base/pytorch-xlm-roberta-base/config.json\n",
      "/kaggle/input/huggingface-roberta-variants/pytorch-xlm-roberta-base/pytorch-xlm-roberta-base/tokenizer.json\n",
      "/kaggle/input/huggingface-roberta-variants/pytorch-xlm-roberta-base/pytorch-xlm-roberta-base/pytorch_model.bin\n",
      "/kaggle/input/huggingface-roberta-variants/pytorch-xlm-roberta-base/pytorch-xlm-roberta-base/sentencepiece.bpe.model\n",
      "/kaggle/input/commonlitreadabilityprize/sample_submission.csv\n",
      "/kaggle/input/commonlitreadabilityprize/train.csv\n",
      "/kaggle/input/commonlitreadabilityprize/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8c175c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:27:47.457884Z",
     "iopub.status.busy": "2021-07-18T19:27:47.456900Z",
     "iopub.status.idle": "2021-07-18T19:27:51.797728Z",
     "shell.execute_reply": "2021-07-18T19:27:51.798144Z",
     "shell.execute_reply.started": "2021-07-18T19:15:10.049670Z"
    },
    "papermill": {
     "duration": 4.366055,
     "end_time": "2021-07-18T19:27:51.798367",
     "exception": false,
     "start_time": "2021-07-18T19:27:47.432312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "from datetime import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import r2_score\n",
    "warnings.filterwarnings('ignore')\n",
    "import re  \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78632c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:27:51.871065Z",
     "iopub.status.busy": "2021-07-18T19:27:51.870225Z",
     "iopub.status.idle": "2021-07-18T19:27:51.995116Z",
     "shell.execute_reply": "2021-07-18T19:27:51.994550Z",
     "shell.execute_reply.started": "2021-07-18T19:15:14.584508Z"
    },
    "papermill": {
     "duration": 0.165799,
     "end_time": "2021-07-18T19:27:51.995253",
     "exception": false,
     "start_time": "2021-07-18T19:27:51.829454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TRAIN\n",
    "data = pd.read_csv('../input/commonlitreadabilityprize/train.csv', header = 0)\n",
    "test = pd.read_csv('../input/commonlitreadabilityprize/test.csv',  header = 0)\n",
    "\n",
    "data['license'].fillna('None', inplace = True)\n",
    "\n",
    "\n",
    "data['excerpt'] = [n.replace('{','') for n in data['excerpt']]\n",
    "data['excerpt'] = [n.replace('}','') for n in data['excerpt']]\n",
    "\n",
    "data['excerpt'] = [n.replace('(','') for n in data['excerpt']]\n",
    "data['excerpt'] = [n.replace(')','') for n in data['excerpt']]\n",
    "data['excerpt'] = [n.replace('.','') for n in data['excerpt']]\n",
    "data['excerpt'] = [n.replace(',','') for n in data['excerpt']]\n",
    "\n",
    "#data['excerpt'] = [n.lower() for n in data['excerpt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cca0be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:27:52.044450Z",
     "iopub.status.busy": "2021-07-18T19:27:52.043103Z",
     "iopub.status.idle": "2021-07-18T19:27:52.045492Z",
     "shell.execute_reply": "2021-07-18T19:27:52.045918Z",
     "shell.execute_reply.started": "2021-07-18T19:15:14.728232Z"
    },
    "papermill": {
     "duration": 0.031706,
     "end_time": "2021-07-18T19:27:52.046055",
     "exception": false,
     "start_time": "2021-07-18T19:27:52.014349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "test['license'].fillna('None', inplace = True)\n",
    "\n",
    "\n",
    "test['excerpt'] = [n.replace('{','') for n in test['excerpt']]\n",
    "test['excerpt'] = [n.replace('}','') for n in test['excerpt']]\n",
    "\n",
    "test['excerpt'] = [n.replace('(','') for n in test['excerpt']]\n",
    "test['excerpt'] = [n.replace(')','') for n in test['excerpt']]\n",
    "test['excerpt'] = [n.replace('.','') for n in test['excerpt']]\n",
    "test['excerpt'] = [n.replace(',','') for n in test['excerpt']]\n",
    "\n",
    "#test['excerpt'] = [n.lower() for n in test['excerpt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a38728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:27:52.086659Z",
     "iopub.status.busy": "2021-07-18T19:27:52.086083Z",
     "iopub.status.idle": "2021-07-18T19:27:52.089643Z",
     "shell.execute_reply": "2021-07-18T19:27:52.090071Z",
     "shell.execute_reply.started": "2021-07-18T19:15:14.740449Z"
    },
    "papermill": {
     "duration": 0.025455,
     "end_time": "2021-07-18T19:27:52.090270",
     "exception": false,
     "start_time": "2021-07-18T19:27:52.064815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_data = data['excerpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce703c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:27:52.133895Z",
     "iopub.status.busy": "2021-07-18T19:27:52.132675Z",
     "iopub.status.idle": "2021-07-18T19:27:52.135010Z",
     "shell.execute_reply": "2021-07-18T19:27:52.135447Z",
     "shell.execute_reply.started": "2021-07-18T19:15:14.749205Z"
    },
    "papermill": {
     "duration": 0.025223,
     "end_time": "2021-07-18T19:27:52.135602",
     "exception": false,
     "start_time": "2021-07-18T19:27:52.110379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################### ROBERTA LARGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12bcf1d8",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-07-18T19:27:52.176766Z",
     "iopub.status.busy": "2021-07-18T19:27:52.176202Z",
     "iopub.status.idle": "2021-07-18T19:28:19.238226Z",
     "shell.execute_reply": "2021-07-18T19:28:19.237791Z",
     "shell.execute_reply.started": "2021-07-18T19:15:14.759543Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 27.084274,
     "end_time": "2021-07-18T19:28:19.238369",
     "exception": false,
     "start_time": "2021-07-18T19:27:52.154095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-roberta-variants/roberta-large/roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "tokenizer_large = RobertaTokenizer.from_pretrained('../input/huggingface-roberta-variants/roberta-large/roberta-large')\n",
    "model_large = RobertaModel.from_pretrained('../input/huggingface-roberta-variants/roberta-large/roberta-large',\n",
    "                                  output_hidden_states = True,# Whether the model returns all hidden-states.\n",
    "                                  ).to(device)\n",
    "\n",
    "model_large.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2f29366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:28:19.291736Z",
     "iopub.status.busy": "2021-07-18T19:28:19.291098Z",
     "iopub.status.idle": "2021-07-18T19:29:56.919510Z",
     "shell.execute_reply": "2021-07-18T19:29:56.919012Z",
     "shell.execute_reply.started": "2021-07-18T19:17:16.552187Z"
    },
    "papermill": {
     "duration": 97.65779,
     "end_time": "2021-07-18T19:29:56.919648",
     "exception": false,
     "start_time": "2021-07-18T19:28:19.261858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:36.159838\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "train_data_large = []\n",
    "with torch.no_grad():\n",
    "  for i in range(len(text_data)):\n",
    "    inputs = tokenizer_large(text_data[i], return_tensors=\"pt\").to(device)\n",
    "    outputs = model_large(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    res = torch.mean(last_hidden_states[0], dim=0)\n",
    "  \n",
    "    train_data_large.append(res.cpu().data.numpy())\n",
    "  print(datetime.now() - start_time)\n",
    "\n",
    "feature_large = [('feature_'+str(i+1)) for i in range(1024)]\n",
    "df_large = pd.DataFrame(train_data_large, columns = feature_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dcb4c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:29:56.964210Z",
     "iopub.status.busy": "2021-07-18T19:29:56.963417Z",
     "iopub.status.idle": "2021-07-18T19:29:56.966175Z",
     "shell.execute_reply": "2021-07-18T19:29:56.965771Z",
     "shell.execute_reply.started": "2021-07-18T19:18:50.275270Z"
    },
    "papermill": {
     "duration": 0.026498,
     "end_time": "2021-07-18T19:29:56.966300",
     "exception": false,
     "start_time": "2021-07-18T19:29:56.939802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_large = df_large\n",
    "y_large = data['target']\n",
    "#X_train_large, X_val_large, y_train_large, y_val_large = train_test_split(X_large,y_large, test_size = 0.05, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1502b6cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:29:57.014025Z",
     "iopub.status.busy": "2021-07-18T19:29:57.012334Z",
     "iopub.status.idle": "2021-07-18T19:30:39.990766Z",
     "shell.execute_reply": "2021-07-18T19:30:39.991297Z",
     "shell.execute_reply.started": "2021-07-18T19:18:50.282960Z"
    },
    "papermill": {
     "duration": 43.005334,
     "end_time": "2021-07-18T19:30:39.991445",
     "exception": false,
     "start_time": "2021-07-18T19:29:56.986111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(cat_smooth=52, colsample_bytree=0.4, learning_rate=0.014,\n",
       "              max_depth=9, metric='rmse', min_child_samples=146,\n",
       "              n_estimators=1700, num_leaves=452, reg_alpha=0.002281458672564199,\n",
       "              reg_lambda=0.6252458927149529, subsample=0.8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_large = {'cat_smooth': 52,\n",
    " 'colsample_bytree': 0.4,\n",
    " 'learning_rate': 0.014,\n",
    " 'max_depth': 9,\n",
    " 'metric': 'rmse',\n",
    " 'min_child_samples': 146,\n",
    " 'n_estimators': 1700,\n",
    " 'num_leaves': 452,\n",
    " 'reg_alpha': 0.002281458672564199,\n",
    " 'reg_lambda': 0.6252458927149529,\n",
    " 'subsample': 0.8}\n",
    "\n",
    "model_roberta_large = lgb.LGBMRegressor(**params_large)\n",
    "model_roberta_large.fit(X_large, y_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e7cb1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:30:40.036677Z",
     "iopub.status.busy": "2021-07-18T19:30:40.035908Z",
     "iopub.status.idle": "2021-07-18T19:30:40.038845Z",
     "shell.execute_reply": "2021-07-18T19:30:40.038413Z",
     "shell.execute_reply.started": "2021-07-18T19:19:32.086546Z"
    },
    "papermill": {
     "duration": 0.0272,
     "end_time": "2021-07-18T19:30:40.038954",
     "exception": false,
     "start_time": "2021-07-18T19:30:40.011754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Roberta large test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6362838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:30:40.084434Z",
     "iopub.status.busy": "2021-07-18T19:30:40.083565Z",
     "iopub.status.idle": "2021-07-18T19:30:40.085900Z",
     "shell.execute_reply": "2021-07-18T19:30:40.086352Z",
     "shell.execute_reply.started": "2021-07-18T19:20:13.852350Z"
    },
    "papermill": {
     "duration": 0.027157,
     "end_time": "2021-07-18T19:30:40.086504",
     "exception": false,
     "start_time": "2021-07-18T19:30:40.059347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_test_large = test['excerpt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be76b5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:30:40.134335Z",
     "iopub.status.busy": "2021-07-18T19:30:40.133547Z",
     "iopub.status.idle": "2021-07-18T19:30:40.445967Z",
     "shell.execute_reply": "2021-07-18T19:30:40.445483Z",
     "shell.execute_reply.started": "2021-07-18T19:24:09.700721Z"
    },
    "papermill": {
     "duration": 0.338844,
     "end_time": "2021-07-18T19:30:40.446097",
     "exception": false,
     "start_time": "2021-07-18T19:30:40.107253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data_large = []\n",
    "with torch.no_grad():\n",
    "  for i in range(len(text_test_large)):\n",
    "    inputs = tokenizer_large(text_test_large[i], return_tensors=\"pt\").to(device)\n",
    "    outputs = model_large(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    res = torch.mean(last_hidden_states[0], dim=0)\n",
    "  \n",
    "    test_data_large.append(res.cpu().data.numpy())\n",
    "df_to_test_large = pd.DataFrame(test_data_large, columns = feature_large)\n",
    "test_id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eed80cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:30:40.500472Z",
     "iopub.status.busy": "2021-07-18T19:30:40.499541Z",
     "iopub.status.idle": "2021-07-18T19:30:40.504118Z",
     "shell.execute_reply": "2021-07-18T19:30:40.503693Z",
     "shell.execute_reply.started": "2021-07-18T19:24:14.082888Z"
    },
    "papermill": {
     "duration": 0.036821,
     "end_time": "2021-07-18T19:30:40.504229",
     "exception": false,
     "start_time": "2021-07-18T19:30:40.467408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_large = model_roberta_large.predict(df_to_test_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef96c86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:30:40.549584Z",
     "iopub.status.busy": "2021-07-18T19:30:40.548809Z",
     "iopub.status.idle": "2021-07-18T19:30:40.551645Z",
     "shell.execute_reply": "2021-07-18T19:30:40.551217Z"
    },
    "papermill": {
     "duration": 0.027163,
     "end_time": "2021-07-18T19:30:40.551758",
     "exception": false,
     "start_time": "2021-07-18T19:30:40.524595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################################################### ROBERTA BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fa7a1e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-07-18T19:30:40.596905Z",
     "iopub.status.busy": "2021-07-18T19:30:40.596400Z",
     "iopub.status.idle": "2021-07-18T19:30:47.435256Z",
     "shell.execute_reply": "2021-07-18T19:30:47.433198Z",
     "shell.execute_reply.started": "2021-07-18T19:20:36.819032Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 6.86334,
     "end_time": "2021-07-18T19:30:47.435542",
     "exception": false,
     "start_time": "2021-07-18T19:30:40.572202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-roberta-variants/roberta-base/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "tokenizer_base = RobertaTokenizer.from_pretrained('../input/huggingface-roberta-variants/roberta-base/roberta-base')\n",
    "model_base = RobertaModel.from_pretrained('../input/huggingface-roberta-variants/roberta-base/roberta-base',\n",
    "                                  output_hidden_states = True,# Whether the model returns all hidden-states.\n",
    "                                  ).to(device)\n",
    "\n",
    "model_base.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec19b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:30:47.536982Z",
     "iopub.status.busy": "2021-07-18T19:30:47.536207Z",
     "iopub.status.idle": "2021-07-18T19:31:28.318843Z",
     "shell.execute_reply": "2021-07-18T19:31:28.319375Z",
     "shell.execute_reply.started": "2021-07-18T19:21:21.042525Z"
    },
    "papermill": {
     "duration": 40.839291,
     "end_time": "2021-07-18T19:31:28.319566",
     "exception": false,
     "start_time": "2021-07-18T19:30:47.480275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_base = []\n",
    "with torch.no_grad():\n",
    "  for i in range(len(text_data)):\n",
    "    inputs = tokenizer_base(text_data[i], return_tensors=\"pt\").to(device)\n",
    "    outputs = model_base(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    res = torch.mean(last_hidden_states[0], dim=0)\n",
    "  \n",
    "    train_data_base.append(res.cpu().data.numpy())\n",
    "\n",
    "feature_base = [('feature_'+str(i+1)) for i in range(768)]\n",
    "df_base = pd.DataFrame(train_data_base, columns = feature_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c6ee3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:31:28.375068Z",
     "iopub.status.busy": "2021-07-18T19:31:28.373783Z",
     "iopub.status.idle": "2021-07-18T19:31:28.376041Z",
     "shell.execute_reply": "2021-07-18T19:31:28.376521Z",
     "shell.execute_reply.started": "2021-07-18T19:22:00.693541Z"
    },
    "papermill": {
     "duration": 0.031666,
     "end_time": "2021-07-18T19:31:28.376655",
     "exception": false,
     "start_time": "2021-07-18T19:31:28.344989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_base = df_base\n",
    "y_base = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcb57086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:31:28.429938Z",
     "iopub.status.busy": "2021-07-18T19:31:28.428316Z",
     "iopub.status.idle": "2021-07-18T19:32:34.377896Z",
     "shell.execute_reply": "2021-07-18T19:32:34.378657Z",
     "shell.execute_reply.started": "2021-07-18T19:22:00.699854Z"
    },
    "papermill": {
     "duration": 65.979536,
     "end_time": "2021-07-18T19:32:34.378873",
     "exception": false,
     "start_time": "2021-07-18T19:31:28.399337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(cat_smooth=93, colsample_bytree=0.5, learning_rate=0.02,\n",
       "              max_depth=6, metric='rmse', min_child_samples=36,\n",
       "              n_estimators=2000, num_leaves=792, reg_alpha=0.006198822217531364,\n",
       "              reg_lambda=6.482243311875356, subsample=0.8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_base = {'cat_smooth': 93,\n",
    " 'colsample_bytree': 0.5,\n",
    " 'learning_rate': 0.02,\n",
    " 'max_depth': 6,\n",
    " 'metric': 'rmse',\n",
    " 'min_child_samples': 36,\n",
    " 'n_estimators': 2000,\n",
    " 'num_leaves': 792,\n",
    " 'reg_alpha': 0.006198822217531364,\n",
    " 'reg_lambda': 6.482243311875356,\n",
    " 'subsample': 0.8}\n",
    "\n",
    "model_roberta_base = lgb.LGBMRegressor(**params_base)\n",
    "model_roberta_base.fit(X_base, y_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a4fbb49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:32:34.462294Z",
     "iopub.status.busy": "2021-07-18T19:32:34.461285Z",
     "iopub.status.idle": "2021-07-18T19:32:34.463808Z",
     "shell.execute_reply": "2021-07-18T19:32:34.463143Z",
     "shell.execute_reply.started": "2021-07-18T19:23:26.954419Z"
    },
    "papermill": {
     "duration": 0.04588,
     "end_time": "2021-07-18T19:32:34.463952",
     "exception": false,
     "start_time": "2021-07-18T19:32:34.418072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "############# ROBERTA base test\n",
    "text_test_base = text_test_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "877bfe2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:32:34.528850Z",
     "iopub.status.busy": "2021-07-18T19:32:34.528044Z",
     "iopub.status.idle": "2021-07-18T19:32:34.677623Z",
     "shell.execute_reply": "2021-07-18T19:32:34.677123Z",
     "shell.execute_reply.started": "2021-07-18T19:24:44.773443Z"
    },
    "papermill": {
     "duration": 0.178585,
     "end_time": "2021-07-18T19:32:34.677755",
     "exception": false,
     "start_time": "2021-07-18T19:32:34.499170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data_base = []\n",
    "with torch.no_grad():\n",
    "  for i in range(len(text_test_base)):\n",
    "    inputs = tokenizer_base(text_test_base[i], return_tensors=\"pt\").to(device)\n",
    "    outputs = model_base(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    res = torch.mean(last_hidden_states[0], dim=0)\n",
    "  \n",
    "    test_data_base.append(res.cpu().data.numpy())\n",
    "    \n",
    "df_to_test_base = pd.DataFrame(test_data_base, columns = feature_base)\n",
    "test_id = test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d24e489f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:32:34.739035Z",
     "iopub.status.busy": "2021-07-18T19:32:34.738098Z",
     "iopub.status.idle": "2021-07-18T19:32:34.742998Z",
     "shell.execute_reply": "2021-07-18T19:32:34.743384Z",
     "shell.execute_reply.started": "2021-07-18T19:26:04.468151Z"
    },
    "papermill": {
     "duration": 0.040181,
     "end_time": "2021-07-18T19:32:34.743530",
     "exception": false,
     "start_time": "2021-07-18T19:32:34.703349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_base = model_roberta_base.predict(df_to_test_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89b77a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:32:34.792905Z",
     "iopub.status.busy": "2021-07-18T19:32:34.792302Z",
     "iopub.status.idle": "2021-07-18T19:32:34.796685Z",
     "shell.execute_reply": "2021-07-18T19:32:34.796160Z",
     "shell.execute_reply.started": "2021-07-18T19:26:14.532569Z"
    },
    "papermill": {
     "duration": 0.030237,
     "end_time": "2021-07-18T19:32:34.796814",
     "exception": false,
     "start_time": "2021-07-18T19:32:34.766577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############################################         UNION TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb08fe53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-18T19:32:34.851675Z",
     "iopub.status.busy": "2021-07-18T19:32:34.851083Z",
     "iopub.status.idle": "2021-07-18T19:32:34.858658Z",
     "shell.execute_reply": "2021-07-18T19:32:34.858122Z",
     "shell.execute_reply.started": "2021-07-18T19:27:14.398541Z"
    },
    "papermill": {
     "duration": 0.036157,
     "end_time": "2021-07-18T19:32:34.858770",
     "exception": false,
     "start_time": "2021-07-18T19:32:34.822613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_union = (pred_base+pred_large)/2\n",
    "\n",
    "my_submission = pd.DataFrame({'id': test_id, 'target': pred_union})\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f7c15",
   "metadata": {
    "papermill": {
     "duration": 0.022717,
     "end_time": "2021-07-18T19:32:34.904221",
     "exception": false,
     "start_time": "2021-07-18T19:32:34.881504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d2ddd2",
   "metadata": {
    "papermill": {
     "duration": 0.024122,
     "end_time": "2021-07-18T19:32:34.954148",
     "exception": false,
     "start_time": "2021-07-18T19:32:34.930026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 297.848383,
   "end_time": "2021-07-18T19:32:38.174823",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-18T19:27:40.326440",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
